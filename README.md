# be_law
Repository for Learning and Wellbeing 2021 (Mentor: Bassam Al-Salemi, PhD; Mentee: Elaine K.)

Download pretrained Universal Sentence Encoder at https://tfhub.dev/google/universal-sentence-encoder-large/5  
The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. The universal-sentence-encoder-large model is trained with a Transformer encoder.

Link to In-house training materials:
https://petronas-my.sharepoint.com/:f:/r/personal/elaine_khoosynnyie_petronas_com/Documents/be_LAW2021?csf=1&web=1&e=hTVZ8b
